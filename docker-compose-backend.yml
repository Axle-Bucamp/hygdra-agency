services:
  fastapi:
    build:
      context: ./Backend/app
    container_name: fastapi-server
    ports:
      - "7060:7060"
    volumes:
      - ./Backend/app:/app
    depends_on:
      - ollama
      - es01
    environment:
      - UVICORN_CMD=uvicorn
      - APP_HOST=0.0.0.0
      - APP_PORT=${PORT}
      - ELASTICSEARCH_HOST=http://es01:9200
      - OLLAMA_URL=http://ollama:11434
    networks:
      - app-agency

  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    networks:
      - app-agency
    command: ["ollama", "pull", "nomic-embed-text", "&&", "ollama", "pull", "codellama"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  code-execution:
    image: python:3.11-slim
    container_name: code_executor
    command: python3 app/code.py  # Executes generated Python code
    volumes:
      - ./Backend/app/generated_code:/app 
      # replace per git clone and jenkins pipeline for live 
      # (template choice : python, node, ...)
    environment:
      - LIMIT_MEMORY=256mb  # Example for limiting resource usage (could use cgroups)
    networks:
      - app-agency
    deploy:
      resources:
        limits:
          cpus: "0.5"  # Limit to half a CPU
          memory: "512M"  # Limit to 256 MB of RAM

  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    volumes:
      - ./Backend/chromedb/data:/chroma/.chroma/index
    ports:
      - 2500:8000
    networks:
      - app-agency

#TODO 
# for production ready instead of local saved code :
# - sonarqube
# - jenkins
# - git 

networks:
  app-agency:
    driver: bridge

